{
  "9": {
    "inputs": {
      "filename_prefix": "Flux2-Klein-4b-base",
      "images": [
        "75:65",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "94": {
    "inputs": {
      "filename_prefix": "Flux2-Klein-4b-base",
      "images": [
        "92:65",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "99": {
    "inputs": {
      "value": "https://upload.wikimedia.org/wikipedia/commons/a/a0/Central_Asian_Women%27s_Adornment_and_Clothing._Two_Women_Wearing_Long_Robes._One_Woman%27s_Hair_Is_Arranged_in_Short%2C_Jewel-Bedecked_Braids%3B_the_Other_Has_Long%2C_Thick_Braids_Down_Her_Back_WDL11191.png",
      "alpha_is_transparency": false
    },
    "class_type": "LoadImageFromURL",
    "_meta": {
      "title": "LoadImageFromURL"
    }
  },
  "100": {
    "inputs": {
      "value": "https://upload.wikimedia.org/wikipedia/commons/7/78/Marc_newson%2C_sedia_embryo%2C_1988.JPG",
      "alpha_is_transparency": false
    },
    "class_type": "LoadImageFromURL",
    "_meta": {
      "title": "LoadImageFromURL"
    }
  },
  "101": {
    "inputs": {
      "resize_mode": "cover",
      "resolutions": "Kontext",
      "interpolation": "lanczos",
      "aspect_ratio_tolerance": 0.05,
      "image": [
        "99",
        0
      ]
    },
    "class_type": "ImageResize",
    "_meta": {
      "title": "Fit Image to Diffusion Size"
    }
  },
  "75:61": {
    "inputs": {
      "sampler_name": "euler"
    },
    "class_type": "KSamplerSelect",
    "_meta": {
      "title": "KSamplerSelect"
    }
  },
  "75:62": {
    "inputs": {
      "steps": 20,
      "width": [
        "75:81",
        0
      ],
      "height": [
        "75:81",
        1
      ]
    },
    "class_type": "Flux2Scheduler",
    "_meta": {
      "title": "Flux2Scheduler"
    }
  },
  "75:63": {
    "inputs": {
      "cfg": 5,
      "model": [
        "75:70",
        0
      ],
      "positive": [
        "75:79:77",
        0
      ],
      "negative": [
        "75:79:76",
        0
      ]
    },
    "class_type": "CFGGuider",
    "_meta": {
      "title": "CFGGuider"
    }
  },
  "75:64": {
    "inputs": {
      "noise": [
        "75:73",
        0
      ],
      "guider": [
        "75:63",
        0
      ],
      "sampler": [
        "75:61",
        0
      ],
      "sigmas": [
        "75:62",
        0
      ],
      "latent_image": [
        "75:66",
        0
      ]
    },
    "class_type": "SamplerCustomAdvanced",
    "_meta": {
      "title": "SamplerCustomAdvanced"
    }
  },
  "75:65": {
    "inputs": {
      "samples": [
        "75:64",
        0
      ],
      "vae": [
        "75:72",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "75:73": {
    "inputs": {
      "noise_seed": 432262096973502
    },
    "class_type": "RandomNoise",
    "_meta": {
      "title": "RandomNoise"
    }
  },
  "75:70": {
    "inputs": {
      "unet_name": "flux-2-klein-base-4b.safetensors",
      "weight_dtype": "default"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "75:71": {
    "inputs": {
      "clip_name": "qwen_3_4b.safetensors",
      "type": "flux2",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "75:74": {
    "inputs": {
      "text": "Change the background to a cozy, softly lit interior space with warm beige tones, soft natural window light filtering through, and a relaxed, intimate atmosphere similar to the original image's mood. Keep the person in the exact same position, scale, and pose. Maintain identical camera angle, framing, and perspective. The lighting should be soft, even, and warm - not harsh or bright. Only replace the room environment, preserving all facial features, hairstyle, expression, clothing, and pose exactly as they are.",
      "clip": [
        "75:71",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive Prompt)"
    }
  },
  "75:67": {
    "inputs": {
      "text": "",
      "clip": [
        "75:71",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Negative Prompt)"
    }
  },
  "75:72": {
    "inputs": {
      "vae_name": "flux2-vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "75:66": {
    "inputs": {
      "width": [
        "75:81",
        0
      ],
      "height": [
        "75:81",
        1
      ],
      "batch_size": 1
    },
    "class_type": "EmptyFlux2LatentImage",
    "_meta": {
      "title": "Empty Flux 2 Latent"
    }
  },
  "75:80": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "megapixels": 1,
      "resolution_steps": 1,
      "image": [
        "101",
        0
      ]
    },
    "class_type": "ImageScaleToTotalPixels",
    "_meta": {
      "title": "ImageScaleToTotalPixels"
    }
  },
  "75:79:76": {
    "inputs": {
      "conditioning": [
        "75:67",
        0
      ],
      "latent": [
        "75:79:78",
        0
      ]
    },
    "class_type": "ReferenceLatent",
    "_meta": {
      "title": "ReferenceLatent"
    }
  },
  "75:79:78": {
    "inputs": {
      "pixels": [
        "75:80",
        0
      ],
      "vae": [
        "75:72",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "75:79:77": {
    "inputs": {
      "conditioning": [
        "75:74",
        0
      ],
      "latent": [
        "75:79:78",
        0
      ]
    },
    "class_type": "ReferenceLatent",
    "_meta": {
      "title": "ReferenceLatent"
    }
  },
  "75:81": {
    "inputs": {
      "image": [
        "75:80",
        0
      ]
    },
    "class_type": "GetImageSize",
    "_meta": {
      "title": "Get Image Size"
    }
  },
  "92:61": {
    "inputs": {
      "sampler_name": "euler"
    },
    "class_type": "KSamplerSelect",
    "_meta": {
      "title": "KSamplerSelect"
    }
  },
  "92:64": {
    "inputs": {
      "noise": [
        "92:73",
        0
      ],
      "guider": [
        "92:63",
        0
      ],
      "sampler": [
        "92:61",
        0
      ],
      "sigmas": [
        "92:62",
        0
      ],
      "latent_image": [
        "92:66",
        0
      ]
    },
    "class_type": "SamplerCustomAdvanced",
    "_meta": {
      "title": "SamplerCustomAdvanced"
    }
  },
  "92:65": {
    "inputs": {
      "samples": [
        "92:64",
        0
      ],
      "vae": [
        "92:72",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "92:73": {
    "inputs": {
      "noise_seed": 432262096973497
    },
    "class_type": "RandomNoise",
    "_meta": {
      "title": "RandomNoise"
    }
  },
  "92:70": {
    "inputs": {
      "unet_name": "flux-2-klein-base-4b.safetensors",
      "weight_dtype": "default"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "92:72": {
    "inputs": {
      "vae_name": "flux2-vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "92:81": {
    "inputs": {
      "image": [
        "92:80",
        0
      ]
    },
    "class_type": "GetImageSize",
    "_meta": {
      "title": "Get Image Size"
    }
  },
  "92:66": {
    "inputs": {
      "width": [
        "92:81",
        0
      ],
      "height": [
        "92:81",
        1
      ],
      "batch_size": 1
    },
    "class_type": "EmptyFlux2LatentImage",
    "_meta": {
      "title": "Empty Flux 2 Latent"
    }
  },
  "92:80": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "megapixels": 1,
      "resolution_steps": 1,
      "image": [
        "101",
        0
      ]
    },
    "class_type": "ImageScaleToTotalPixels",
    "_meta": {
      "title": "ImageScaleToTotalPixels"
    }
  },
  "92:85": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "megapixels": 1,
      "resolution_steps": 1,
      "image": [
        "100",
        0
      ]
    },
    "class_type": "ImageScaleToTotalPixels",
    "_meta": {
      "title": "ImageScaleToTotalPixels"
    }
  },
  "92:84:76": {
    "inputs": {
      "conditioning": [
        "92:79:76",
        0
      ],
      "latent": [
        "92:84:78",
        0
      ]
    },
    "class_type": "ReferenceLatent",
    "_meta": {
      "title": "ReferenceLatent"
    }
  },
  "92:84:78": {
    "inputs": {
      "pixels": [
        "92:85",
        0
      ],
      "vae": [
        "92:72",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "92:84:77": {
    "inputs": {
      "conditioning": [
        "92:79:77",
        0
      ],
      "latent": [
        "92:84:78",
        0
      ]
    },
    "class_type": "ReferenceLatent",
    "_meta": {
      "title": "ReferenceLatent"
    }
  },
  "92:71": {
    "inputs": {
      "clip_name": "qwen_3_4b.safetensors",
      "type": "flux2",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "92:79:76": {
    "inputs": {
      "conditioning": [
        "92:87",
        0
      ],
      "latent": [
        "92:79:78",
        0
      ]
    },
    "class_type": "ReferenceLatent",
    "_meta": {
      "title": "ReferenceLatent"
    }
  },
  "92:79:78": {
    "inputs": {
      "pixels": [
        "92:80",
        0
      ],
      "vae": [
        "92:72",
        0
      ]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "92:79:77": {
    "inputs": {
      "conditioning": [
        "92:74",
        0
      ],
      "latent": [
        "92:79:78",
        0
      ]
    },
    "class_type": "ReferenceLatent",
    "_meta": {
      "title": "ReferenceLatent"
    }
  },
  "92:74": {
    "inputs": {
      "text": "A stylish young woman with dark skin wearing a plush deep emerald green bathrobe, light pink towel turban, and red heart-shaped sunglasses, seated on a light-colored rattan chair with soft pink cushions, positioned in front of a textured dusty rose pink wall with an arched alcove, large tropical plants with broad dark green leaves framing both sides, woven straw baskets on the floor, remove any existing shoes from the background, only the woman's beige woven sandals visible in the foreground, soft natural lighting casting gentle shadows, warm bohemian chic aesthetic, professional fashion photography",
      "clip": [
        "92:71",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive Prompt)"
    }
  },
  "92:87": {
    "inputs": {
      "text": "",
      "clip": [
        "92:71",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode ( Negative Prompt)"
    }
  },
  "92:63": {
    "inputs": {
      "cfg": 5,
      "model": [
        "92:70",
        0
      ],
      "positive": [
        "92:84:77",
        0
      ],
      "negative": [
        "92:84:76",
        0
      ]
    },
    "class_type": "CFGGuider",
    "_meta": {
      "title": "CFGGuider"
    }
  },
  "92:62": {
    "inputs": {
      "steps": 20,
      "width": [
        "92:81",
        0
      ],
      "height": [
        "92:81",
        1
      ]
    },
    "class_type": "Flux2Scheduler",
    "_meta": {
      "title": "Flux2Scheduler"
    }
  }
}