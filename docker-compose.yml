name: "comfyui"
services:
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      # USING DOCKER MANAGED VOLUMES
      - workspace_data:/workspace
      # OR: USE LOCAL DIRECTORIES
      # Comment out the `- workspace_data...` line, then uncomment:
      # - models:/workspace/models
      # - custom_nodes:/workspace/custom_nodes
      # - output:/workspace/output
      # - input:/workspace/input
    deploy:
      replicas: 1
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    environment:
      - COMFYUI_DISTRIBUTED_QUEUE_CONNECTION_URI=amqp://guest:guest@rabbitmq:5672
      - COMFYUI_PANIC_WHEN=torch.cuda.OutOfMemoryError
      - COMFYUI_LOGGING_LEVEL=ERROR
    command:
      - comfyui-worker
    healthcheck:
      test: curl -f http://localhost:9090/health
      interval: 10s
      timeout: 5s
      retries: 1
      start_period: 10s
    restart: unless-stopped
  frontend:
    build:
      context: .
      dockerfile: Dockerfile
    deploy:
      replicas: 1
    volumes:
      # USING DOCKER MANAGED VOLUMES
      - workspace_data:/workspace
      # OR: USE LOCAL DIRECTORIES
      # Comment out the `- workspace_data...` line, then uncomment:
      # - models:/workspace/models
      # - custom_nodes:/workspace/custom_nodes
      # - output:/workspace/output
      # - input:/workspace/input
    environment:
      - COMFYUI_DISTRIBUTED_QUEUE_CONNECTION_URI=amqp://guest:guest@rabbitmq:5672
      - COMFYUI_DISTRIBUTED_QUEUE_FRONTEND=1
      - COMFYUI_LOGGING_LEVEL=INFO
    ports:
      - "8188:8188"
    command:
      - comfyui
      - --listen
    healthcheck:
      test: curl -f http://localhost:8188/object_info
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    restart: unless-stopped
  rabbitmq:
    image: rabbitmq:3
    command: >
      sh -c "echo 'log.default.level = error' > /etc/rabbitmq/rabbitmq.conf && 
             docker-entrypoint.sh rabbitmq-server"
volumes:
  # USING DOCKER MANAGED VOLUMES
  workspace_data: {}
  # OR: USE LOCAL DIRECTORIES
  # models:
  #   driver: local
  #   driver_opts:
  #     type: 'none'
  #     o: 'bind'
  #     device: './models'
  # custom_nodes:
  #   driver: local
  #   driver_opts:
  #     type: 'none'
  #     o: 'bind'
  #     device: './custom_nodes'
  # output:
  #   driver: local
  #   driver_opts:
  #     type: 'none'
  #     o: 'bind'
  #     device: './output'
  # input:
  #   driver: local
  #   driver_opts:
  #     type: 'none'
  #     o: 'bind'
  #     device: './input'